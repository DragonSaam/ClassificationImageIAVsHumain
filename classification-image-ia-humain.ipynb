{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1959fa0a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:12.363777Z",
     "iopub.status.busy": "2025-03-02T21:30:12.363342Z",
     "iopub.status.idle": "2025-03-02T21:30:13.214926Z",
     "shell.execute_reply": "2025-03-02T21:30:13.213902Z"
    },
    "papermill": {
     "duration": 0.859747,
     "end_time": "2025-03-02T21:30:13.217198",
     "exception": false,
     "start_time": "2025-03-02T21:30:12.357451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5ffda4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:13.233874Z",
     "iopub.status.busy": "2025-03-02T21:30:13.233427Z",
     "iopub.status.idle": "2025-03-02T21:30:22.416753Z",
     "shell.execute_reply": "2025-03-02T21:30:22.415826Z"
    },
    "papermill": {
     "duration": 9.193359,
     "end_time": "2025-03-02T21:30:22.418479",
     "exception": false,
     "start_time": "2025-03-02T21:30:13.225120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import Bibliotheques - Import Library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7594c35",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:22.428007Z",
     "iopub.status.busy": "2025-03-02T21:30:22.427591Z",
     "iopub.status.idle": "2025-03-02T21:30:22.695791Z",
     "shell.execute_reply": "2025-03-02T21:30:22.694527Z"
    },
    "papermill": {
     "duration": 0.274506,
     "end_time": "2025-03-02T21:30:22.697405",
     "exception": false,
     "start_time": "2025-03-02T21:30:22.422899",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                          file_name  label\n",
      "0           0  /kaggle/input/ai-vs-human-generated-dataset/tr...      1\n",
      "1           1  /kaggle/input/ai-vs-human-generated-dataset/tr...      0\n",
      "2           2  /kaggle/input/ai-vs-human-generated-dataset/tr...      1\n",
      "3           3  /kaggle/input/ai-vs-human-generated-dataset/tr...      0\n",
      "4           4  /kaggle/input/ai-vs-human-generated-dataset/tr...      1\n"
     ]
    }
   ],
   "source": [
    "#Importation des fichiers csv et création du chemin de récupération des images\n",
    "#Import CSV files and create recuperation path for images\n",
    "\n",
    "folder_path = \"/kaggle/input/ai-vs-human-generated-dataset\"\n",
    "train_csv_path = '/kaggle/input/ai-vs-human-generated-dataset/train.csv'\n",
    "train_csv = pd.read_csv(train_csv_path)\n",
    "\n",
    "def get_image_path(folder_path, image_name) :\n",
    "    return os.path.join(folder_path, image_name)\n",
    "\n",
    "#Ajout du chemin complet de l'image dans file_name\n",
    "#Add complet path of the image in the colomns file_name\n",
    "train_csv['file_name'] = train_csv['file_name'].apply(lambda name : get_image_path(folder_path, name))\n",
    "\n",
    "\n",
    "print(train_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aceb88a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:22.707670Z",
     "iopub.status.busy": "2025-03-02T21:30:22.707367Z",
     "iopub.status.idle": "2025-03-02T21:30:22.726357Z",
     "shell.execute_reply": "2025-03-02T21:30:22.725694Z"
    },
    "papermill": {
     "duration": 0.025574,
     "end_time": "2025-03-02T21:30:22.727852",
     "exception": false,
     "start_time": "2025-03-02T21:30:22.702278",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Chargement d'un Dataset léger pour tester mon code\n",
    "#Low weight dataset loding - in order to test my code before the big loading\n",
    "train_test_csv = train_csv.head(1000)\n",
    "train_data_set = train_test_csv\n",
    "\n",
    "#Chargement du Dataset complet\n",
    "#Full dataset loading\n",
    "train_data_set = train_csv\n",
    "\n",
    "df = pd.DataFrame(train_data_set)\n",
    "\n",
    "#Dataset splité\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "089e4c3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:22.738118Z",
     "iopub.status.busy": "2025-03-02T21:30:22.737848Z",
     "iopub.status.idle": "2025-03-02T21:30:22.742290Z",
     "shell.execute_reply": "2025-03-02T21:30:22.741526Z"
    },
    "papermill": {
     "duration": 0.011138,
     "end_time": "2025-03-02T21:30:22.743883",
     "exception": false,
     "start_time": "2025-03-02T21:30:22.732745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Définir des transformations\n",
    "#Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((384, 384)),  # Taille requise pour ConvNeXt\n",
    "    transforms.RandomHorizontalFlip(),  # Rotation aléatoire jusqu'à 15°\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),       # Convertir en tenseur PyTorch\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation ImageNet\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a66d426",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:22.753761Z",
     "iopub.status.busy": "2025-03-02T21:30:22.753509Z",
     "iopub.status.idle": "2025-03-02T21:30:22.759211Z",
     "shell.execute_reply": "2025-03-02T21:30:22.758301Z"
    },
    "papermill": {
     "duration": 0.012129,
     "end_time": "2025-03-02T21:30:22.760572",
     "exception": false,
     "start_time": "2025-03-02T21:30:22.748443",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Création d'un DataLoader avec une classe\n",
    "#Dataloader own class creation\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['file_name']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "\n",
    "        # Charger l'image\n",
    "        # load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Appliquer les transformations si spécifiées\n",
    "        # Apply transformation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61853563",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:22.769703Z",
     "iopub.status.busy": "2025-03-02T21:30:22.769359Z",
     "iopub.status.idle": "2025-03-02T21:30:22.773342Z",
     "shell.execute_reply": "2025-03-02T21:30:22.772448Z"
    },
    "papermill": {
     "duration": 0.009781,
     "end_time": "2025-03-02T21:30:22.774526",
     "exception": false,
     "start_time": "2025-03-02T21:30:22.764745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Création d'une instance de DataSet customisé\n",
    "#Dataset with transformation creation\n",
    "\n",
    "#custom_dataset = CustomDataset(df, transform=transform)\n",
    "#Dataset splité\n",
    "train_dataset = CustomDataset(train_df, transform=transform)\n",
    "val_dataset = CustomDataset(val_df, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3f9b824",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:22.783099Z",
     "iopub.status.busy": "2025-03-02T21:30:22.782867Z",
     "iopub.status.idle": "2025-03-02T21:30:22.786941Z",
     "shell.execute_reply": "2025-03-02T21:30:22.786208Z"
    },
    "papermill": {
     "duration": 0.009902,
     "end_time": "2025-03-02T21:30:22.788300",
     "exception": false,
     "start_time": "2025-03-02T21:30:22.778398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Création d'un Dataloader pour itération des données\n",
    "#Dataloader for data iteration\n",
    "\n",
    "#custom_loader = DataLoader(custom_dataset, batch_size=32, shuffle=True)\n",
    "#Dataset splité\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2671695a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:22.797518Z",
     "iopub.status.busy": "2025-03-02T21:30:22.797268Z",
     "iopub.status.idle": "2025-03-02T21:30:26.840550Z",
     "shell.execute_reply": "2025-03-02T21:30:26.839529Z"
    },
    "papermill": {
     "duration": 4.049724,
     "end_time": "2025-03-02T21:30:26.842250",
     "exception": false,
     "start_time": "2025-03-02T21:30:22.792526",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/convnext_base-6075fbad.pth\" to /root/.cache/torch/hub/checkpoints/convnext_base-6075fbad.pth\n",
      "100%|██████████| 338M/338M [00:01<00:00, 186MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle ConvNeXt pré-entraîné d'origine\n",
    "model = models.convnext_base(weights=\"DEFAULT\")\n",
    "# Adapter la dernière couche pour une sortie binaire\n",
    "num_features = model.classifier[2].in_features\n",
    "model.classifier[2] = nn.Sequential(\n",
    "    nn.Linear(num_features, 1),  # Une seule sortie pour binaire\n",
    "    nn.Sigmoid()  # Activation sigmoïde pour probabilité\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b31ea01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:26.854617Z",
     "iopub.status.busy": "2025-03-02T21:30:26.854309Z",
     "iopub.status.idle": "2025-03-02T21:30:26.857732Z",
     "shell.execute_reply": "2025-03-02T21:30:26.856809Z"
    },
    "papermill": {
     "duration": 0.010942,
     "end_time": "2025-03-02T21:30:26.859222",
     "exception": false,
     "start_time": "2025-03-02T21:30:26.848280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#print(os.listdir(\"/kaggle/input/convnext_model_sys_v3_epoque4_lr00005/pytorch/default/1/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2ffb7d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:26.871503Z",
     "iopub.status.busy": "2025-03-02T21:30:26.871202Z",
     "iopub.status.idle": "2025-03-02T21:30:30.384307Z",
     "shell.execute_reply": "2025-03-02T21:30:30.383365Z"
    },
    "papermill": {
     "duration": 3.520811,
     "end_time": "2025-03-02T21:30:30.385796",
     "exception": false,
     "start_time": "2025-03-02T21:30:26.864985",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-f0660642926d>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/input/convnext_model_sys_v3_epoque4_lr00005/pytorch/default/1/convnext_model_SYS_V3_Epoque4_lr00005.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.014285714285714285, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02857142857142857, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.04285714285714286, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05714285714285714, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07142857142857142, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08571428571428572, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11428571428571428, mode=row)\n",
       "      )\n",
       "      (3): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12857142857142856, mode=row)\n",
       "      )\n",
       "      (4): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14285714285714285, mode=row)\n",
       "      )\n",
       "      (5): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15714285714285714, mode=row)\n",
       "      )\n",
       "      (6): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17142857142857143, mode=row)\n",
       "      )\n",
       "      (7): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18571428571428572, mode=row)\n",
       "      )\n",
       "      (8): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "      )\n",
       "      (9): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.21428571428571427, mode=row)\n",
       "      )\n",
       "      (10): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.22857142857142856, mode=row)\n",
       "      )\n",
       "      (11): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.24285714285714285, mode=row)\n",
       "      )\n",
       "      (12): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2571428571428571, mode=row)\n",
       "      )\n",
       "      (13): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2714285714285714, mode=row)\n",
       "      )\n",
       "      (14): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2857142857142857, mode=row)\n",
       "      )\n",
       "      (15): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "      )\n",
       "      (16): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.3142857142857143, mode=row)\n",
       "      )\n",
       "      (17): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.32857142857142857, mode=row)\n",
       "      )\n",
       "      (18): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.34285714285714286, mode=row)\n",
       "      )\n",
       "      (19): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.35714285714285715, mode=row)\n",
       "      )\n",
       "      (20): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.37142857142857144, mode=row)\n",
       "      )\n",
       "      (21): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.38571428571428573, mode=row)\n",
       "      )\n",
       "      (22): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4, mode=row)\n",
       "      )\n",
       "      (23): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4142857142857143, mode=row)\n",
       "      )\n",
       "      (24): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.42857142857142855, mode=row)\n",
       "      )\n",
       "      (25): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.44285714285714284, mode=row)\n",
       "      )\n",
       "      (26): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.45714285714285713, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4714285714285714, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4857142857142857, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le modèle sauvegardé\n",
    "import kagglehub\n",
    "#convnext_model_sys_pytorch_default_1_path = kagglehub.model_download('/kaggle/input/convnext_model_sys/pytorch/default/1/convnext_model_SYS.pth')\n",
    "\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/convnext_model_sys_v3_epoque4_lr00005/pytorch/default/1/convnext_model_SYS_V3_Epoque4_lr00005.pth\"))\n",
    "model.train()  # Remettre le modèle en mode entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8f4657c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:30.400280Z",
     "iopub.status.busy": "2025-03-02T21:30:30.400013Z",
     "iopub.status.idle": "2025-03-02T21:30:30.559811Z",
     "shell.execute_reply": "2025-03-02T21:30:30.558678Z"
    },
    "papermill": {
     "duration": 0.16836,
     "end_time": "2025-03-02T21:30:30.561482",
     "exception": false,
     "start_time": "2025-03-02T21:30:30.393122",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Déplacer le modèle sur le GPU si disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "007bb314",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:30.574963Z",
     "iopub.status.busy": "2025-03-02T21:30:30.574700Z",
     "iopub.status.idle": "2025-03-02T21:30:30.579877Z",
     "shell.execute_reply": "2025-03-02T21:30:30.579079Z"
    },
    "papermill": {
     "duration": 0.013184,
     "end_time": "2025-03-02T21:30:30.581092",
     "exception": false,
     "start_time": "2025-03-02T21:30:30.567908",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Définir la fonction de perte et l'optimiseur\n",
    "#Define lost function and optimiser\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b99085b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-02T21:30:30.594066Z",
     "iopub.status.busy": "2025-03-02T21:30:30.593804Z",
     "iopub.status.idle": "2025-03-03T05:56:11.202131Z",
     "shell.execute_reply": "2025-03-03T05:56:11.201206Z"
    },
    "papermill": {
     "duration": 30340.624544,
     "end_time": "2025-03-03T05:56:11.211640",
     "exception": false,
     "start_time": "2025-03-02T21:30:30.587096",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1, Perte entraînement : 0.0655, Perte validation : 0.0674, Exactitude validation : 97.47%\n",
      "Époque 2, Perte entraînement : 0.0575, Perte validation : 0.0572, Exactitude validation : 97.95%\n",
      "Époque 3, Perte entraînement : 0.0460, Perte validation : 0.0407, Exactitude validation : 98.61%\n"
     ]
    }
   ],
   "source": [
    "#Entraînement du modèle\n",
    "#Fit model\n",
    "# Entraînement du modèle\n",
    "for epoch in range(3):  # Nombre d'époques\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.view(-1, 1)  # Adapter les dimensions des labels\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass et optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Évaluation sur l'ensemble de validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.view(-1, 1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            correct += (predictions.view(-1) == labels.view(-1)).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Époque {epoch+1}, Perte entraînement : {running_loss/len(train_loader):.4f}, Perte validation : {val_loss/len(val_loader):.4f}, Exactitude validation : {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9769bcc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T05:56:11.225820Z",
     "iopub.status.busy": "2025-03-03T05:56:11.225504Z",
     "iopub.status.idle": "2025-03-03T06:00:54.243734Z",
     "shell.execute_reply": "2025-03-03T06:00:54.242769Z"
    },
    "papermill": {
     "duration": 283.032616,
     "end_time": "2025-03-03T06:00:54.250792",
     "exception": false,
     "start_time": "2025-03-03T05:56:11.218176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitude : 98.65%\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct += (predictions.view(-1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Exactitude : {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a4a6d327",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T06:00:54.264356Z",
     "iopub.status.busy": "2025-03-03T06:00:54.264038Z",
     "iopub.status.idle": "2025-03-03T06:00:54.729892Z",
     "shell.execute_reply": "2025-03-03T06:00:54.728927Z"
    },
    "papermill": {
     "duration": 0.474548,
     "end_time": "2025-03-03T06:00:54.731696",
     "exception": false,
     "start_time": "2025-03-03T06:00:54.257148",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle\n",
    "torch.save(model.state_dict(), 'convnext_model_SYS_V4_Epoque7_lr00005.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d57f85ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T06:00:54.745800Z",
     "iopub.status.busy": "2025-03-03T06:00:54.745509Z",
     "iopub.status.idle": "2025-03-03T06:00:54.748613Z",
     "shell.execute_reply": "2025-03-03T06:00:54.747892Z"
    },
    "papermill": {
     "duration": 0.011585,
     "end_time": "2025-03-03T06:00:54.749903",
     "exception": false,
     "start_time": "2025-03-03T06:00:54.738318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Charger le modèle pour l'inférence\n",
    "#model.load_state_dict(torch.load('convnext_model_SYS.pth', map_location=device))\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3f6be4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.006072,
     "end_time": "2025-03-03T06:00:54.762184",
     "exception": false,
     "start_time": "2025-03-03T06:00:54.756112",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**CLASSIFICATION DES IMAGES TEST NON ETIQUETEES - UNLABELED IMAGES CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4763028d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T06:00:54.776150Z",
     "iopub.status.busy": "2025-03-03T06:00:54.775860Z",
     "iopub.status.idle": "2025-03-03T06:00:54.807657Z",
     "shell.execute_reply": "2025-03-03T06:00:54.806752Z"
    },
    "papermill": {
     "duration": 0.040446,
     "end_time": "2025-03-03T06:00:54.809011",
     "exception": false,
     "start_time": "2025-03-03T06:00:54.768565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    test_data_v2/1a2d9fd3e21b4266aea1f66b30aed157.jpg\n",
      "1    test_data_v2/ab5df8f441fe4fbf9dc9c6baae699dc7.jpg\n",
      "2    test_data_v2/eb364dd2dfe34feda0e52466b7ce7956.jpg\n",
      "3    test_data_v2/f76c2580e9644d85a741a42c6f6b39c0.jpg\n",
      "4    test_data_v2/a16495c578b7494683805484ca27cf9f.jpg\n",
      "Name: id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Préparation des données de test final\n",
    "#Final test data preparation\n",
    "test_csv_path = '/kaggle/input/ai-vs-human-generated-dataset/test.csv'\n",
    "test_csv = pd.read_csv(test_csv_path)\n",
    "id_csv = test_csv['id']\n",
    "test_csv['id'] = test_csv['id'].apply(lambda name : get_image_path(folder_path, name))\n",
    "\n",
    "#Chargement d'un Dataset léger pour tester mon code\n",
    "#Low weight dataset loding - in order to test my code before the big loading\n",
    "test_test_csv = test_csv.head(50)\n",
    "test_data_set = test_test_csv\n",
    "\n",
    "#Chargement du Dataset complet\n",
    "#Full dataset loading\n",
    "test_data_set = test_csv\n",
    "\n",
    "#Création du DataFrame de test\n",
    "#Test Dataframe creation\n",
    "df_test = pd.DataFrame(test_data_set)\n",
    "print(id_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "31e13299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T06:00:54.823097Z",
     "iopub.status.busy": "2025-03-03T06:00:54.822815Z",
     "iopub.status.idle": "2025-03-03T06:00:54.828958Z",
     "shell.execute_reply": "2025-03-03T06:00:54.828200Z"
    },
    "papermill": {
     "duration": 0.014762,
     "end_time": "2025-03-03T06:00:54.830193",
     "exception": false,
     "start_time": "2025-03-03T06:00:54.815431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Création d'un DataLoader_test avec une classe\n",
    "#Dataloader own class creation\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['id']\n",
    "\n",
    "        # Charger l'image\n",
    "        # load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Appliquer les transformations si spécifiées\n",
    "        # Apply transformation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.dataframe.iloc[idx]['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd2dec0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T06:00:54.844466Z",
     "iopub.status.busy": "2025-03-03T06:00:54.844173Z",
     "iopub.status.idle": "2025-03-03T06:00:54.848505Z",
     "shell.execute_reply": "2025-03-03T06:00:54.847467Z"
    },
    "papermill": {
     "duration": 0.012679,
     "end_time": "2025-03-03T06:00:54.849836",
     "exception": false,
     "start_time": "2025-03-03T06:00:54.837157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Création d'une instance de DataSet customisé\n",
    "#Dataset with transformation creation\n",
    "custom_dataset_test = CustomDataset(df_test, transform=transform)\n",
    "\n",
    "#Création d'un Dataloader pour itération des données\n",
    "#Dataloader for data iteration\n",
    "custom_loader_test = DataLoader(custom_dataset_test, batch_size=16, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bc56ee42",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T06:00:54.864217Z",
     "iopub.status.busy": "2025-03-03T06:00:54.863940Z",
     "iopub.status.idle": "2025-03-03T06:00:54.867344Z",
     "shell.execute_reply": "2025-03-03T06:00:54.866653Z"
    },
    "papermill": {
     "duration": 0.012341,
     "end_time": "2025-03-03T06:00:54.868707",
     "exception": false,
     "start_time": "2025-03-03T06:00:54.856366",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Liste pour stocker les résultats\n",
    "results = []\n",
    "id_counter = 0  # Initialisation du compteur d'ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a7d890d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T06:00:54.883397Z",
     "iopub.status.busy": "2025-03-03T06:00:54.883106Z",
     "iopub.status.idle": "2025-03-03T06:02:51.449824Z",
     "shell.execute_reply": "2025-03-03T06:02:51.448676Z"
    },
    "papermill": {
     "duration": 116.582663,
     "end_time": "2025-03-03T06:02:51.458164",
     "exception": false,
     "start_time": "2025-03-03T06:00:54.875501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier CSV généré : predictions.csv\n",
      "                                                     id  label\n",
      "0     test_data_v2/1a2d9fd3e21b4266aea1f66b30aed157.jpg      0\n",
      "1     test_data_v2/ab5df8f441fe4fbf9dc9c6baae699dc7.jpg      1\n",
      "2     test_data_v2/eb364dd2dfe34feda0e52466b7ce7956.jpg      0\n",
      "3     test_data_v2/f76c2580e9644d85a741a42c6f6b39c0.jpg      0\n",
      "4     test_data_v2/a16495c578b7494683805484ca27cf9f.jpg      0\n",
      "...                                                 ...    ...\n",
      "5535  test_data_v2/483412064ff74d9d9472d606b65976d9.jpg      1\n",
      "5536  test_data_v2/c0b49ba4081a4197b422dac7c15aea7f.jpg      0\n",
      "5537  test_data_v2/01454aaedec140c0a3ca1f48028c41cf.jpg      0\n",
      "5538  test_data_v2/e9adfea8b67e4791968c4c2bdd8ec343.jpg      0\n",
      "5539  test_data_v2/ba8f4198e8d74d3394fa56c56af23442.jpg      0\n",
      "\n",
      "[5540 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Itérer sur le DataLoader et faire des prédictions\n",
    "# Prédictions sur les données non étiquetées\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, _) in enumerate(custom_loader_test):  # On ignore le label puisque les images sont non étiquetées\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions = (outputs > 0.5).int()  # Convertir les probabilités en 0/1\n",
    "\n",
    "        # Ajouter chaque prédiction au tableau des résultats\n",
    "        for pred in predictions.cpu().numpy():\n",
    "            #results.append({'id': len(results) + 1, 'label': int(pred)})\n",
    "            results.append({'id': id_csv[id_counter], 'label': int(pred.item() if hasattr(pred, 'item') else pred)})\n",
    "            id_counter += 1  # Incrémenter le compteur\n",
    "\n",
    "\n",
    "# Convertir en DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sauvegarder le DataFrame en fichier CSV\n",
    "output_csv_path = \"predictions.csv\"\n",
    "#results_df.to_csv(output_csv_path, index=False, sep=';')\n",
    "results_df.to_csv(output_csv_path, index=False, sep=',')\n",
    "\n",
    "print(f\"Fichier CSV généré : {output_csv_path}\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "233c0371",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-03T06:02:51.472818Z",
     "iopub.status.busy": "2025-03-03T06:02:51.472519Z",
     "iopub.status.idle": "2025-03-03T06:02:51.478123Z",
     "shell.execute_reply": "2025-03-03T06:02:51.477150Z"
    },
    "papermill": {
     "duration": 0.014446,
     "end_time": "2025-03-03T06:02:51.479480",
     "exception": false,
     "start_time": "2025-03-03T06:02:51.465034",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='predictions.csv' target='_blank'>predictions.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/predictions.csv"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(\"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10884264,
     "sourceId": 91198,
     "sourceType": "competition"
    },
    {
     "datasetId": 6412205,
     "sourceId": 10550636,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 252710,
     "modelInstanceId": 230953,
     "sourceId": 269877,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 253828,
     "modelInstanceId": 232096,
     "sourceId": 271149,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 255561,
     "modelInstanceId": 233847,
     "sourceId": 273128,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 30764.551987,
   "end_time": "2025-03-03T06:02:53.966589",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-03-02T21:30:09.414602",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
