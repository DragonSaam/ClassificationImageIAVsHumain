{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89078e28",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:27.424553Z",
     "iopub.status.busy": "2025-02-28T13:32:27.424241Z",
     "iopub.status.idle": "2025-02-28T13:32:28.150011Z",
     "shell.execute_reply": "2025-02-28T13:32:28.149315Z"
    },
    "papermill": {
     "duration": 0.733194,
     "end_time": "2025-02-28T13:32:28.151577",
     "exception": false,
     "start_time": "2025-02-28T13:32:27.418383",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "#for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#    for filename in filenames:\n",
    "#        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e8bf10d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:28.160794Z",
     "iopub.status.busy": "2025-02-28T13:32:28.160466Z",
     "iopub.status.idle": "2025-02-28T13:32:36.553235Z",
     "shell.execute_reply": "2025-02-28T13:32:36.552272Z"
    },
    "papermill": {
     "duration": 8.398831,
     "end_time": "2025-02-28T13:32:36.554802",
     "exception": false,
     "start_time": "2025-02-28T13:32:28.155971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import Bibliotheques - Import Library\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0a055c86",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:36.564175Z",
     "iopub.status.busy": "2025-02-28T13:32:36.563723Z",
     "iopub.status.idle": "2025-02-28T13:32:36.786856Z",
     "shell.execute_reply": "2025-02-28T13:32:36.785882Z"
    },
    "papermill": {
     "duration": 0.229044,
     "end_time": "2025-02-28T13:32:36.788331",
     "exception": false,
     "start_time": "2025-02-28T13:32:36.559287",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                          file_name  label\n",
      "0           0  /kaggle/input/ai-vs-human-generated-dataset/tr...      1\n",
      "1           1  /kaggle/input/ai-vs-human-generated-dataset/tr...      0\n",
      "2           2  /kaggle/input/ai-vs-human-generated-dataset/tr...      1\n",
      "3           3  /kaggle/input/ai-vs-human-generated-dataset/tr...      0\n",
      "4           4  /kaggle/input/ai-vs-human-generated-dataset/tr...      1\n"
     ]
    }
   ],
   "source": [
    "#Importation des fichiers csv et création du chemin de récupération des images\n",
    "#Import CSV files and create recuperation path for images\n",
    "\n",
    "folder_path = \"/kaggle/input/ai-vs-human-generated-dataset\"\n",
    "train_csv_path = '/kaggle/input/ai-vs-human-generated-dataset/train.csv'\n",
    "train_csv = pd.read_csv(train_csv_path)\n",
    "\n",
    "def get_image_path(folder_path, image_name) :\n",
    "    return os.path.join(folder_path, image_name)\n",
    "\n",
    "#Ajout du chemin complet de l'image dans file_name\n",
    "#Add complet path of the image in the colomns file_name\n",
    "train_csv['file_name'] = train_csv['file_name'].apply(lambda name : get_image_path(folder_path, name))\n",
    "\n",
    "\n",
    "print(train_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "28a5762b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:36.797605Z",
     "iopub.status.busy": "2025-02-28T13:32:36.797340Z",
     "iopub.status.idle": "2025-02-28T13:32:36.816081Z",
     "shell.execute_reply": "2025-02-28T13:32:36.815225Z"
    },
    "papermill": {
     "duration": 0.024649,
     "end_time": "2025-02-28T13:32:36.817400",
     "exception": false,
     "start_time": "2025-02-28T13:32:36.792751",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Chargement d'un Dataset léger pour tester mon code\n",
    "#Low weight dataset loding - in order to test my code before the big loading\n",
    "train_test_csv = train_csv.head(1000)\n",
    "train_data_set = train_test_csv\n",
    "\n",
    "#Chargement du Dataset complet\n",
    "#Full dataset loading\n",
    "train_data_set = train_csv\n",
    "\n",
    "df = pd.DataFrame(train_data_set)\n",
    "\n",
    "#Dataset splité\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "val_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12b04473",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:36.825980Z",
     "iopub.status.busy": "2025-02-28T13:32:36.825731Z",
     "iopub.status.idle": "2025-02-28T13:32:36.829850Z",
     "shell.execute_reply": "2025-02-28T13:32:36.829056Z"
    },
    "papermill": {
     "duration": 0.009702,
     "end_time": "2025-02-28T13:32:36.831048",
     "exception": false,
     "start_time": "2025-02-28T13:32:36.821346",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Définir des transformations\n",
    "#Define transformations\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # Taille requise pour ConvNeXt\n",
    "    transforms.RandomHorizontalFlip(),  # Rotation aléatoire jusqu'à 15°\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),       # Convertir en tenseur PyTorch\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation ImageNet\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b563521",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:36.839472Z",
     "iopub.status.busy": "2025-02-28T13:32:36.839241Z",
     "iopub.status.idle": "2025-02-28T13:32:36.844055Z",
     "shell.execute_reply": "2025-02-28T13:32:36.843061Z"
    },
    "papermill": {
     "duration": 0.010493,
     "end_time": "2025-02-28T13:32:36.845440",
     "exception": false,
     "start_time": "2025-02-28T13:32:36.834947",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Création d'un DataLoader avec une classe\n",
    "#Dataloader own class creation\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['file_name']\n",
    "        label = self.dataframe.iloc[idx]['label']\n",
    "\n",
    "        # Charger l'image\n",
    "        # load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Appliquer les transformations si spécifiées\n",
    "        # Apply transformation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, torch.tensor(label, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d05efd83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:36.854101Z",
     "iopub.status.busy": "2025-02-28T13:32:36.853833Z",
     "iopub.status.idle": "2025-02-28T13:32:36.857062Z",
     "shell.execute_reply": "2025-02-28T13:32:36.856470Z"
    },
    "papermill": {
     "duration": 0.008846,
     "end_time": "2025-02-28T13:32:36.858267",
     "exception": false,
     "start_time": "2025-02-28T13:32:36.849421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Création d'une instance de DataSet customisé\n",
    "#Dataset with transformation creation\n",
    "\n",
    "#custom_dataset = CustomDataset(df, transform=transform)\n",
    "#Dataset splité\n",
    "train_dataset = CustomDataset(train_df, transform=transform)\n",
    "val_dataset = CustomDataset(val_df, transform=transform)\n",
    "test_dataset = CustomDataset(test_df, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbd96790",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:36.866817Z",
     "iopub.status.busy": "2025-02-28T13:32:36.866609Z",
     "iopub.status.idle": "2025-02-28T13:32:36.870390Z",
     "shell.execute_reply": "2025-02-28T13:32:36.869762Z"
    },
    "papermill": {
     "duration": 0.009212,
     "end_time": "2025-02-28T13:32:36.871449",
     "exception": false,
     "start_time": "2025-02-28T13:32:36.862237",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Création d'un Dataloader pour itération des données\n",
    "#Dataloader for data iteration\n",
    "\n",
    "#custom_loader = DataLoader(custom_dataset, batch_size=32, shuffle=True)\n",
    "#Dataset splité\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb5fce4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:36.880073Z",
     "iopub.status.busy": "2025-02-28T13:32:36.879808Z",
     "iopub.status.idle": "2025-02-28T13:32:40.628746Z",
     "shell.execute_reply": "2025-02-28T13:32:40.627467Z"
    },
    "papermill": {
     "duration": 3.755683,
     "end_time": "2025-02-28T13:32:40.631018",
     "exception": false,
     "start_time": "2025-02-28T13:32:36.875335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ConvNeXt_Base_Weights.IMAGENET1K_V1`. You can also use `weights=ConvNeXt_Base_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/convnext_base-6075fbad.pth\" to /root/.cache/torch/hub/checkpoints/convnext_base-6075fbad.pth\n",
      "100%|██████████| 338M/338M [00:01<00:00, 191MB/s]\n"
     ]
    }
   ],
   "source": [
    "# Charger le modèle ConvNeXt pré-entraîné d'origine\n",
    "model = models.convnext_base(pretrained=True)\n",
    "# Adapter la dernière couche pour une sortie binaire\n",
    "num_features = model.classifier[2].in_features\n",
    "model.classifier[2] = nn.Sequential(\n",
    "    nn.Linear(num_features, 1),  # Une seule sortie pour binaire\n",
    "    nn.Sigmoid()  # Activation sigmoïde pour probabilité\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4b42feb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:40.647938Z",
     "iopub.status.busy": "2025-02-28T13:32:40.647560Z",
     "iopub.status.idle": "2025-02-28T13:32:40.651293Z",
     "shell.execute_reply": "2025-02-28T13:32:40.650338Z"
    },
    "papermill": {
     "duration": 0.015078,
     "end_time": "2025-02-28T13:32:40.653022",
     "exception": false,
     "start_time": "2025-02-28T13:32:40.637944",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#import os\n",
    "#print(os.listdir(\"/kaggle/input/convnext_model_sys_v2_epoque4/pytorch/default/1/convnext_model_SYS_V2_Epoque4.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e17f987",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:40.672074Z",
     "iopub.status.busy": "2025-02-28T13:32:40.671720Z",
     "iopub.status.idle": "2025-02-28T13:32:44.599790Z",
     "shell.execute_reply": "2025-02-28T13:32:44.598732Z"
    },
    "papermill": {
     "duration": 3.939378,
     "end_time": "2025-02-28T13:32:44.601164",
     "exception": false,
     "start_time": "2025-02-28T13:32:40.661786",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-529b9ffec7cd>:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"/kaggle/input/convnext_model_sys_v2_epoque4/pytorch/default/1/convnext_model_SYS_V2_Epoque4.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ConvNeXt(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 128, kernel_size=(4, 4), stride=(4, 4))\n",
       "      (1): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.014285714285714285, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(128, 128, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=128)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((128,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.02857142857142857, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): LayerNorm2d((128,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.04285714285714286, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05714285714285714, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(256, 256, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=256)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((256,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=256, out_features=1024, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=1024, out_features=256, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07142857142857142, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): LayerNorm2d((256,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(256, 512, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08571428571428572, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.11428571428571428, mode=row)\n",
       "      )\n",
       "      (3): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.12857142857142856, mode=row)\n",
       "      )\n",
       "      (4): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.14285714285714285, mode=row)\n",
       "      )\n",
       "      (5): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15714285714285714, mode=row)\n",
       "      )\n",
       "      (6): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17142857142857143, mode=row)\n",
       "      )\n",
       "      (7): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.18571428571428572, mode=row)\n",
       "      )\n",
       "      (8): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2, mode=row)\n",
       "      )\n",
       "      (9): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.21428571428571427, mode=row)\n",
       "      )\n",
       "      (10): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.22857142857142856, mode=row)\n",
       "      )\n",
       "      (11): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.24285714285714285, mode=row)\n",
       "      )\n",
       "      (12): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2571428571428571, mode=row)\n",
       "      )\n",
       "      (13): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2714285714285714, mode=row)\n",
       "      )\n",
       "      (14): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.2857142857142857, mode=row)\n",
       "      )\n",
       "      (15): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.3, mode=row)\n",
       "      )\n",
       "      (16): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.3142857142857143, mode=row)\n",
       "      )\n",
       "      (17): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.32857142857142857, mode=row)\n",
       "      )\n",
       "      (18): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.34285714285714286, mode=row)\n",
       "      )\n",
       "      (19): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.35714285714285715, mode=row)\n",
       "      )\n",
       "      (20): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.37142857142857144, mode=row)\n",
       "      )\n",
       "      (21): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.38571428571428573, mode=row)\n",
       "      )\n",
       "      (22): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4, mode=row)\n",
       "      )\n",
       "      (23): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4142857142857143, mode=row)\n",
       "      )\n",
       "      (24): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.42857142857142855, mode=row)\n",
       "      )\n",
       "      (25): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.44285714285714284, mode=row)\n",
       "      )\n",
       "      (26): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(512, 512, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=512)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.45714285714285713, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): LayerNorm2d((512,), eps=1e-06, elementwise_affine=True)\n",
       "      (1): Conv2d(512, 1024, kernel_size=(2, 2), stride=(2, 2))\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4714285714285714, mode=row)\n",
       "      )\n",
       "      (1): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.4857142857142857, mode=row)\n",
       "      )\n",
       "      (2): CNBlock(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2d(1024, 1024, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1024)\n",
       "          (1): Permute()\n",
       "          (2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)\n",
       "          (3): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (4): GELU(approximate='none')\n",
       "          (5): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (6): Permute()\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.5, mode=row)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): LayerNorm2d((1024,), eps=1e-06, elementwise_affine=True)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Sequential(\n",
       "      (0): Linear(in_features=1024, out_features=1, bias=True)\n",
       "      (1): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Charger le modèle sauvegardé\n",
    "import kagglehub\n",
    "#convnext_model_sys_pytorch_default_1_path = kagglehub.model_download('/kaggle/input/convnext_model_sys/pytorch/default/1/convnext_model_SYS.pth')\n",
    "\n",
    "model.load_state_dict(torch.load(\"/kaggle/input/convnext_model_sys_v2_epoque4/pytorch/default/1/convnext_model_SYS_V2_Epoque4.pth\"))\n",
    "model.train()  # Remettre le modèle en mode entraînement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "adabb45f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:44.613548Z",
     "iopub.status.busy": "2025-02-28T13:32:44.613284Z",
     "iopub.status.idle": "2025-02-28T13:32:44.749513Z",
     "shell.execute_reply": "2025-02-28T13:32:44.748570Z"
    },
    "papermill": {
     "duration": 0.143912,
     "end_time": "2025-02-28T13:32:44.751103",
     "exception": false,
     "start_time": "2025-02-28T13:32:44.607191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Déplacer le modèle sur le GPU si disponible\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "#print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d04529",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:44.763339Z",
     "iopub.status.busy": "2025-02-28T13:32:44.763082Z",
     "iopub.status.idle": "2025-02-28T13:32:44.767833Z",
     "shell.execute_reply": "2025-02-28T13:32:44.767063Z"
    },
    "papermill": {
     "duration": 0.012081,
     "end_time": "2025-02-28T13:32:44.769106",
     "exception": false,
     "start_time": "2025-02-28T13:32:44.757025",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Définir la fonction de perte et l'optimiseur\n",
    "#Define lost function and optimiser\n",
    "criterion = nn.BCELoss()  # Binary Cross-Entropy Loss\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f92c9766",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T13:32:44.780713Z",
     "iopub.status.busy": "2025-02-28T13:32:44.780502Z",
     "iopub.status.idle": "2025-02-28T19:32:13.326975Z",
     "shell.execute_reply": "2025-02-28T19:32:13.325961Z"
    },
    "papermill": {
     "duration": 21568.559663,
     "end_time": "2025-02-28T19:32:13.334214",
     "exception": false,
     "start_time": "2025-02-28T13:32:44.774551",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Époque 1, Perte entraînement : 0.1292, Perte validation : 0.1069, Exactitude validation : 95.77%\n",
      "Époque 2, Perte entraînement : 0.1162, Perte validation : 0.1048, Exactitude validation : 95.97%\n",
      "Époque 3, Perte entraînement : 0.1027, Perte validation : 0.0810, Exactitude validation : 96.86%\n",
      "Époque 4, Perte entraînement : 0.0870, Perte validation : 0.0565, Exactitude validation : 97.96%\n",
      "Époque 5, Perte entraînement : 0.0686, Perte validation : 0.0587, Exactitude validation : 97.87%\n",
      "Époque 6, Perte entraînement : 0.0595, Perte validation : 0.0613, Exactitude validation : 97.59%\n"
     ]
    }
   ],
   "source": [
    "#Entraînement du modèle\n",
    "#Fit model\n",
    "# Entraînement du modèle\n",
    "for epoch in range(6):  # Nombre d'époques\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        labels = labels.view(-1, 1)  # Adapter les dimensions des labels\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass et optimisation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Évaluation sur l'ensemble de validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            labels = labels.view(-1, 1)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            predictions = (outputs > 0.5).float()\n",
    "            correct += (predictions.view(-1) == labels.view(-1)).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    val_accuracy = 100 * correct / total\n",
    "    print(f\"Époque {epoch+1}, Perte entraînement : {running_loss/len(train_loader):.4f}, Perte validation : {val_loss/len(val_loader):.4f}, Exactitude validation : {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad26e58a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:32:13.346901Z",
     "iopub.status.busy": "2025-02-28T19:32:13.346652Z",
     "iopub.status.idle": "2025-02-28T19:34:39.514315Z",
     "shell.execute_reply": "2025-02-28T19:34:39.513311Z"
    },
    "papermill": {
     "duration": 146.181912,
     "end_time": "2025-02-28T19:34:39.522126",
     "exception": false,
     "start_time": "2025-02-28T19:32:13.340214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exactitude : 97.26%\n"
     ]
    }
   ],
   "source": [
    "# Évaluation du modèle\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions = (outputs > 0.5).float()\n",
    "        correct += (predictions.view(-1) == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "print(f\"Exactitude : {100 * correct / total:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b2fe468",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:34:39.534714Z",
     "iopub.status.busy": "2025-02-28T19:34:39.534495Z",
     "iopub.status.idle": "2025-02-28T19:34:39.972600Z",
     "shell.execute_reply": "2025-02-28T19:34:39.971813Z"
    },
    "papermill": {
     "duration": 0.446286,
     "end_time": "2025-02-28T19:34:39.974353",
     "exception": false,
     "start_time": "2025-02-28T19:34:39.528067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sauvegarder le modèle\n",
    "torch.save(model.state_dict(), 'convnext_model_SYS_V2_Epoque10.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6873ee79",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:34:39.992090Z",
     "iopub.status.busy": "2025-02-28T19:34:39.991674Z",
     "iopub.status.idle": "2025-02-28T19:34:39.995481Z",
     "shell.execute_reply": "2025-02-28T19:34:39.994583Z"
    },
    "papermill": {
     "duration": 0.014761,
     "end_time": "2025-02-28T19:34:39.997113",
     "exception": false,
     "start_time": "2025-02-28T19:34:39.982352",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Charger le modèle pour l'inférence\n",
    "#model.load_state_dict(torch.load('convnext_model_SYS.pth', map_location=device))\n",
    "#model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a19f034",
   "metadata": {
    "papermill": {
     "duration": 0.007394,
     "end_time": "2025-02-28T19:34:40.011964",
     "exception": false,
     "start_time": "2025-02-28T19:34:40.004570",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**CLASSIFICATION DES IMAGES TEST NON ETIQUETEES - UNLABELED IMAGES CLASSIFICATION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f673c382",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:34:40.028439Z",
     "iopub.status.busy": "2025-02-28T19:34:40.028201Z",
     "iopub.status.idle": "2025-02-28T19:34:40.053288Z",
     "shell.execute_reply": "2025-02-28T19:34:40.052599Z"
    },
    "papermill": {
     "duration": 0.03327,
     "end_time": "2025-02-28T19:34:40.054496",
     "exception": false,
     "start_time": "2025-02-28T19:34:40.021226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    test_data_v2/1a2d9fd3e21b4266aea1f66b30aed157.jpg\n",
      "1    test_data_v2/ab5df8f441fe4fbf9dc9c6baae699dc7.jpg\n",
      "2    test_data_v2/eb364dd2dfe34feda0e52466b7ce7956.jpg\n",
      "3    test_data_v2/f76c2580e9644d85a741a42c6f6b39c0.jpg\n",
      "4    test_data_v2/a16495c578b7494683805484ca27cf9f.jpg\n",
      "Name: id, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#Préparation des données de test final\n",
    "#Final test data preparation\n",
    "test_csv_path = '/kaggle/input/ai-vs-human-generated-dataset/test.csv'\n",
    "test_csv = pd.read_csv(test_csv_path)\n",
    "id_csv = test_csv['id']\n",
    "test_csv['id'] = test_csv['id'].apply(lambda name : get_image_path(folder_path, name))\n",
    "\n",
    "#Chargement d'un Dataset léger pour tester mon code\n",
    "#Low weight dataset loding - in order to test my code before the big loading\n",
    "test_test_csv = test_csv.head(50)\n",
    "test_data_set = test_test_csv\n",
    "\n",
    "#Chargement du Dataset complet\n",
    "#Full dataset loading\n",
    "test_data_set = test_csv\n",
    "\n",
    "#Création du DataFrame de test\n",
    "#Test Dataframe creation\n",
    "df_test = pd.DataFrame(test_data_set)\n",
    "print(id_csv.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aaa9e167",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:34:40.068078Z",
     "iopub.status.busy": "2025-02-28T19:34:40.067816Z",
     "iopub.status.idle": "2025-02-28T19:34:40.072435Z",
     "shell.execute_reply": "2025-02-28T19:34:40.071744Z"
    },
    "papermill": {
     "duration": 0.012634,
     "end_time": "2025-02-28T19:34:40.073524",
     "exception": false,
     "start_time": "2025-02-28T19:34:40.060890",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Création d'un DataLoader_test avec une classe\n",
    "#Dataloader own class creation\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, dataframe, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.dataframe.iloc[idx]['id']\n",
    "\n",
    "        # Charger l'image\n",
    "        # load image\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Appliquer les transformations si spécifiées\n",
    "        # Apply transformation\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, self.dataframe.iloc[idx]['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "36164807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:34:40.086131Z",
     "iopub.status.busy": "2025-02-28T19:34:40.085856Z",
     "iopub.status.idle": "2025-02-28T19:34:40.089786Z",
     "shell.execute_reply": "2025-02-28T19:34:40.088879Z"
    },
    "papermill": {
     "duration": 0.011658,
     "end_time": "2025-02-28T19:34:40.091124",
     "exception": false,
     "start_time": "2025-02-28T19:34:40.079466",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Création d'une instance de DataSet customisé\n",
    "#Dataset with transformation creation\n",
    "custom_dataset_test = CustomDataset(df_test, transform=transform)\n",
    "\n",
    "#Création d'un Dataloader pour itération des données\n",
    "#Dataloader for data iteration\n",
    "custom_loader_test = DataLoader(custom_dataset_test, batch_size=32, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a4663003",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:34:40.103909Z",
     "iopub.status.busy": "2025-02-28T19:34:40.103674Z",
     "iopub.status.idle": "2025-02-28T19:34:40.106799Z",
     "shell.execute_reply": "2025-02-28T19:34:40.106009Z"
    },
    "papermill": {
     "duration": 0.010838,
     "end_time": "2025-02-28T19:34:40.108093",
     "exception": false,
     "start_time": "2025-02-28T19:34:40.097255",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Liste pour stocker les résultats\n",
    "results = []\n",
    "id_counter = 0  # Initialisation du compteur d'ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "34a2c3ad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:34:40.120852Z",
     "iopub.status.busy": "2025-02-28T19:34:40.120629Z",
     "iopub.status.idle": "2025-02-28T19:35:55.089327Z",
     "shell.execute_reply": "2025-02-28T19:35:55.088301Z"
    },
    "papermill": {
     "duration": 74.981808,
     "end_time": "2025-02-28T19:35:55.095960",
     "exception": false,
     "start_time": "2025-02-28T19:34:40.114152",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fichier CSV généré : predictions.csv\n",
      "                                                     id  label\n",
      "0     test_data_v2/1a2d9fd3e21b4266aea1f66b30aed157.jpg      0\n",
      "1     test_data_v2/ab5df8f441fe4fbf9dc9c6baae699dc7.jpg      0\n",
      "2     test_data_v2/eb364dd2dfe34feda0e52466b7ce7956.jpg      0\n",
      "3     test_data_v2/f76c2580e9644d85a741a42c6f6b39c0.jpg      0\n",
      "4     test_data_v2/a16495c578b7494683805484ca27cf9f.jpg      0\n",
      "...                                                 ...    ...\n",
      "5535  test_data_v2/483412064ff74d9d9472d606b65976d9.jpg      0\n",
      "5536  test_data_v2/c0b49ba4081a4197b422dac7c15aea7f.jpg      0\n",
      "5537  test_data_v2/01454aaedec140c0a3ca1f48028c41cf.jpg      0\n",
      "5538  test_data_v2/e9adfea8b67e4791968c4c2bdd8ec343.jpg      0\n",
      "5539  test_data_v2/ba8f4198e8d74d3394fa56c56af23442.jpg      0\n",
      "\n",
      "[5540 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Itérer sur le DataLoader et faire des prédictions\n",
    "# Prédictions sur les données non étiquetées\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for i, (inputs, _) in enumerate(custom_loader_test):  # On ignore le label puisque les images sont non étiquetées\n",
    "        inputs = inputs.to(device)\n",
    "        outputs = model(inputs)\n",
    "        predictions = (outputs > 0.5).int()  # Convertir les probabilités en 0/1\n",
    "\n",
    "        # Ajouter chaque prédiction au tableau des résultats\n",
    "        for pred in predictions.cpu().numpy():\n",
    "            #results.append({'id': len(results) + 1, 'label': int(pred)})\n",
    "            results.append({'id': id_csv[id_counter], 'label': int(pred.item() if hasattr(pred, 'item') else pred)})\n",
    "            id_counter += 1  # Incrémenter le compteur\n",
    "\n",
    "\n",
    "# Convertir en DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Sauvegarder le DataFrame en fichier CSV\n",
    "output_csv_path = \"predictions.csv\"\n",
    "#results_df.to_csv(output_csv_path, index=False, sep=';')\n",
    "results_df.to_csv(output_csv_path, index=False, sep=',')\n",
    "\n",
    "print(f\"Fichier CSV généré : {output_csv_path}\")\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0cb5a467",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-28T19:35:55.109365Z",
     "iopub.status.busy": "2025-02-28T19:35:55.109092Z",
     "iopub.status.idle": "2025-02-28T19:35:55.114186Z",
     "shell.execute_reply": "2025-02-28T19:35:55.113361Z"
    },
    "papermill": {
     "duration": 0.013207,
     "end_time": "2025-02-28T19:35:55.115433",
     "exception": false,
     "start_time": "2025-02-28T19:35:55.102226",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='predictions.csv' target='_blank'>predictions.csv</a><br>"
      ],
      "text/plain": [
       "/kaggle/working/predictions.csv"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import FileLink\n",
    "FileLink(\"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 10884264,
     "sourceId": 91198,
     "sourceType": "competition"
    },
    {
     "datasetId": 6412205,
     "sourceId": 10550636,
     "sourceType": "datasetVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 252710,
     "modelInstanceId": 230953,
     "sourceId": 269877,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 253828,
     "modelInstanceId": 232096,
     "sourceId": 271149,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30839,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21812.747921,
   "end_time": "2025-02-28T19:35:57.530537",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-28T13:32:24.782616",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
