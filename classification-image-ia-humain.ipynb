{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":91198,"databundleVersionId":10739357,"sourceType":"competition"},{"sourceId":10420750,"sourceType":"datasetVersion","datasetId":6412205}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:07:24.931034Z","iopub.execute_input":"2025-01-19T15:07:24.931392Z","iopub.status.idle":"2025-01-19T15:07:25.342795Z","shell.execute_reply.started":"2025-01-19T15:07:24.931363Z","shell.execute_reply":"2025-01-19T15:07:25.341848Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Import Bibliotheques - Import Library\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import models, transforms\nfrom PIL import Image\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:07:31.676751Z","iopub.execute_input":"2025-01-19T15:07:31.677310Z","iopub.status.idle":"2025-01-19T15:07:39.913792Z","shell.execute_reply.started":"2025-01-19T15:07:31.677276Z","shell.execute_reply":"2025-01-19T15:07:39.912595Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Importation des fichiers csv et création du chemin de récupération des images\n#Import CSV files and create recuperation path for images\n\nfolder_path = \"/kaggle/input/ai-vs-human-generated-dataset\"\ntrain_csv_path = '/kaggle/input/ai-vs-human-generated-dataset/train.csv'\ntrain_csv = pd.read_csv(train_csv_path)\n\ndef get_image_path(folder_path, image_name) :\n    return os.path.join(folder_path, image_name)\n\n#Ajout du chemin complet de l'image dans file_name\n#Add complet path of the image in the colomns file_name\ntrain_csv['file_name'] = train_csv['file_name'].apply(lambda name : get_image_path(folder_path, name))\n\n\nprint(train_csv.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:07:50.700860Z","iopub.execute_input":"2025-01-19T15:07:50.701467Z","iopub.status.idle":"2025-01-19T15:07:50.911982Z","shell.execute_reply.started":"2025-01-19T15:07:50.701415Z","shell.execute_reply":"2025-01-19T15:07:50.910868Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Chargement d'un Dataset léger pour tester mon code\n#Low weight dataset loding - in order to test my code before the big loading\ntrain_test_csv = train_csv.head(1000)\ntrain_data_set = train_test_csv\n\n#Chargement du Dataset complet\n#Full dataset loading\ntrain_data_set = train_csv\n\ndf = pd.DataFrame(train_data_set)\n\n#Dataset splité\ntrain_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\nval_df, test_df = train_test_split(test_df, test_size=0.5, random_state=42)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:07:57.035458Z","iopub.execute_input":"2025-01-19T15:07:57.035828Z","iopub.status.idle":"2025-01-19T15:07:57.049225Z","shell.execute_reply.started":"2025-01-19T15:07:57.035789Z","shell.execute_reply":"2025-01-19T15:07:57.048054Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Définir des transformations\n#Define transformations\ntransform = transforms.Compose([\n    transforms.Resize((224, 244)),  # Redimensionner toutes les images\n    transforms.RandomRotation(15),  # Rotation aléatoire jusqu'à 15°\n    transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),  # Recadrage aléatoire\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2), # Variations de couleur\n    transforms.ToTensor(),       # Convertir en tenseur PyTorch\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation ImageNet\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:08:02.643075Z","iopub.execute_input":"2025-01-19T15:08:02.643416Z","iopub.status.idle":"2025-01-19T15:08:02.649902Z","shell.execute_reply.started":"2025-01-19T15:08:02.643391Z","shell.execute_reply":"2025-01-19T15:08:02.648583Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Création d'un DataLoader avec une classe\n#Dataloader own class creation\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_path = self.dataframe.iloc[idx]['file_name']\n        label = self.dataframe.iloc[idx]['label']\n\n        # Charger l'image\n        # load image\n        image = Image.open(img_path).convert(\"RGB\")\n\n        # Appliquer les transformations si spécifiées\n        # Apply transformation\n        if self.transform:\n            image = self.transform(image)\n\n        return image, torch.tensor(label, dtype=torch.float32)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:08:10.989947Z","iopub.execute_input":"2025-01-19T15:08:10.990386Z","iopub.status.idle":"2025-01-19T15:08:10.998697Z","shell.execute_reply.started":"2025-01-19T15:08:10.990345Z","shell.execute_reply":"2025-01-19T15:08:10.997017Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Création d'une instance de DataSet customisé\n#Dataset with transformation creation\n\n#custom_dataset = CustomDataset(df, transform=transform)\n#Dataset splité\ntrain_dataset = CustomDataset(train_df, transform=transform)\nval_dataset = CustomDataset(val_df, transform=transform)\ntest_dataset = CustomDataset(test_df, transform=transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:08:14.243527Z","iopub.execute_input":"2025-01-19T15:08:14.243937Z","iopub.status.idle":"2025-01-19T15:08:14.249807Z","shell.execute_reply.started":"2025-01-19T15:08:14.243904Z","shell.execute_reply":"2025-01-19T15:08:14.248194Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Création d'un Dataloader pour itération des données\n#Dataloader for data iteration\n\n#custom_loader = DataLoader(custom_dataset, batch_size=32, shuffle=True)\n#Dataset splité\ntrain_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=4)\nval_loader = DataLoader(val_dataset, batch_size=64, shuffle=False, num_workers=4)\ntest_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:08:17.389240Z","iopub.execute_input":"2025-01-19T15:08:17.389600Z","iopub.status.idle":"2025-01-19T15:08:17.395380Z","shell.execute_reply.started":"2025-01-19T15:08:17.389563Z","shell.execute_reply":"2025-01-19T15:08:17.394259Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Charger le modèle EfficientNet-B0 pré-entraîné\nmodel = models.efficientnet_b0(pretrained=True)\n\n# Remplacer la dernière couche pour un problème binaire\nnum_features = model.classifier[1].in_features  # La deuxième couche dans 'classifier' est linéaire\nmodel.classifier = nn.Sequential(\n    nn.Linear(num_features, 1),  # Une seule sortie pour la classification binaire\n    nn.Sigmoid()  # Activation pour les probabilités\n)\n\n# Déplacer le modèle sur le GPU si disponible\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\n#print(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:18:00.453824Z","iopub.execute_input":"2025-01-19T15:18:00.454224Z","iopub.status.idle":"2025-01-19T15:18:00.613443Z","shell.execute_reply.started":"2025-01-19T15:18:00.454198Z","shell.execute_reply":"2025-01-19T15:18:00.612462Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Définir la fonction de perte et l'optimiseur\n#Define lost function and optimiser\ncriterion = nn.BCELoss()  # Binary Cross-Entropy Loss\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:18:07.318971Z","iopub.execute_input":"2025-01-19T15:18:07.319541Z","iopub.status.idle":"2025-01-19T15:18:07.326283Z","shell.execute_reply.started":"2025-01-19T15:18:07.319488Z","shell.execute_reply":"2025-01-19T15:18:07.325045Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Entraînement du modèle 1\n#Fit model 1\n# Entraînement du modèle\nfor epoch in range(5):  # Nombre d'époques\n    model.train()\n    running_loss = 0.0\n    for inputs, labels in train_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        labels = labels.view(-1, 1)  # Adapter les dimensions des labels\n\n        # Forward pass\n        outputs = model(inputs)\n        loss = criterion(outputs, labels)\n\n        # Backward pass et optimisation\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    # Évaluation sur l'ensemble de validation\n    model.eval()\n    val_loss = 0.0\n    correct = 0\n    total = 0\n    with torch.no_grad():\n        for inputs, labels in val_loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            labels = labels.view(-1, 1)\n\n            outputs = model(inputs)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n\n            predictions = (outputs > 0.5).float()\n            correct += (predictions.view(-1) == labels.view(-1)).sum().item()\n            total += labels.size(0)\n\n    val_accuracy = 100 * correct / total\n    print(f\"Époque {epoch+1}, Perte entraînement : {running_loss/len(train_loader):.4f}, Perte validation : {val_loss/len(val_loader):.4f}, Exactitude validation : {val_accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:18:16.169181Z","iopub.execute_input":"2025-01-19T15:18:16.169546Z","iopub.status.idle":"2025-01-19T15:31:17.167781Z","shell.execute_reply.started":"2025-01-19T15:18:16.169514Z","shell.execute_reply":"2025-01-19T15:31:17.166010Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Évaluation du modèle\nmodel.eval()\ncorrect = 0\ntotal = 0\nwith torch.no_grad():\n    for inputs, labels in test_loader:\n        inputs, labels = inputs.to(device), labels.to(device)\n        outputs = model(inputs)\n        predictions = (outputs > 0.5).float()\n        correct += (predictions.view(-1) == labels).sum().item()\n        total += labels.size(0)\n\nprint(f\"Exactitude : {100 * correct / total:.2f}%\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:31:38.079085Z","iopub.execute_input":"2025-01-19T15:31:38.079519Z","iopub.status.idle":"2025-01-19T15:31:46.572952Z","shell.execute_reply.started":"2025-01-19T15:31:38.079468Z","shell.execute_reply":"2025-01-19T15:31:46.571375Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**CLASSIFICATION DES IMAGES TEST NON ETIQUETEES - UNLABELED IMAGES CLASSIFICATION**","metadata":{}},{"cell_type":"code","source":"#Préparation des données de test final\n#Final test data preparation\ntest_csv_path = '/kaggle/input/ai-vs-human-generated-dataset/test.csv'\ntest_csv = pd.read_csv(test_csv_path)\ntest_csv['id'] = test_csv['id'].apply(lambda name : get_image_path(folder_path, name))\n\n#Chargement d'un Dataset léger pour tester mon code\n#Low weight dataset loding - in order to test my code before the big loading\ntest_test_csv = test_csv.head(50)\ntest_data_set = test_test_csv\n\n#Chargement du Dataset complet\n#Full dataset loading\n#test_data_set = test_csv\n\n#Création du DataFrame de test\n#Test Dataframe creation\ndf_test = pd.DataFrame(test_data_set)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:32:17.551576Z","iopub.execute_input":"2025-01-19T15:32:17.552018Z","iopub.status.idle":"2025-01-19T15:32:17.626428Z","shell.execute_reply.started":"2025-01-19T15:32:17.551983Z","shell.execute_reply":"2025-01-19T15:32:17.624873Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Création d'un DataLoader_test avec une classe\n#Dataloader own class creation\nclass CustomDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        img_path = self.dataframe.iloc[idx]['id']\n\n        # Charger l'image\n        # load image\n        image = Image.open(img_path).convert(\"RGB\")\n\n        # Appliquer les transformations si spécifiées\n        # Apply transformation\n        if self.transform:\n            image = self.transform(image)\n\n        return image, self.dataframe.iloc[idx]['id']\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:32:31.574842Z","iopub.execute_input":"2025-01-19T15:32:31.575239Z","iopub.status.idle":"2025-01-19T15:32:31.582211Z","shell.execute_reply.started":"2025-01-19T15:32:31.575207Z","shell.execute_reply":"2025-01-19T15:32:31.580393Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#Création d'une instance de DataSet customisé\n#Dataset with transformation creation\ncustom_dataset_test = CustomDataset(df_test, transform=transform)\n\n#Création d'un Dataloader pour itération des données\n#Dataloader for data iteration\ncustom_loader_test = DataLoader(custom_dataset_test, batch_size=32, shuffle=True, num_workers=4)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T15:32:36.904584Z","iopub.execute_input":"2025-01-19T15:32:36.905069Z","iopub.status.idle":"2025-01-19T15:32:36.911375Z","shell.execute_reply.started":"2025-01-19T15:32:36.905033Z","shell.execute_reply":"2025-01-19T15:32:36.910254Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Liste pour stocker les résultats\nresults = []\nid_counter = 1  # Initialisation du compteur d'ID","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:16:45.810931Z","iopub.execute_input":"2025-01-19T16:16:45.811370Z","iopub.status.idle":"2025-01-19T16:16:45.816606Z","shell.execute_reply.started":"2025-01-19T16:16:45.811332Z","shell.execute_reply":"2025-01-19T16:16:45.815207Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Itérer sur le DataLoader et faire des prédictions\n# Prédictions sur les données non étiquetées\nmodel.eval()\nwith torch.no_grad():\n    for i, (inputs, _) in enumerate(custom_loader_test):  # On ignore le label puisque les images sont non étiquetées\n        inputs = inputs.to(device)\n        outputs = model(inputs)\n        predictions = (outputs > 0.5).int()  # Convertir les probabilités en 0/1\n\n        # Ajouter chaque prédiction au tableau des résultats\n        for pred in predictions.cpu().numpy():\n            #results.append({'id': len(results) + 1, 'label': int(pred)})\n            results.append({'id': id_counter, 'label': int(pred.item() if hasattr(pred, 'item') else pred)})\n            id_counter += 1  # Incrémenter le compteur\n\n\n# Convertir en DataFrame\nresults_df = pd.DataFrame(results)\n\n# Sauvegarder le DataFrame en fichier CSV\noutput_csv_path = \"predictions.csv\"\nresults_df.to_csv(output_csv_path, index=False, sep=';')\n\nprint(f\"Fichier CSV généré : {output_csv_path}\")\n#print(results_df)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:16:49.233496Z","iopub.execute_input":"2025-01-19T16:16:49.233974Z","iopub.status.idle":"2025-01-19T16:16:53.553493Z","shell.execute_reply.started":"2025-01-19T16:16:49.233932Z","shell.execute_reply":"2025-01-19T16:16:53.552257Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from IPython.display import FileLink\nFileLink(output_csv_path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-19T16:17:05.841181Z","iopub.execute_input":"2025-01-19T16:17:05.841530Z","iopub.status.idle":"2025-01-19T16:17:05.849176Z","shell.execute_reply.started":"2025-01-19T16:17:05.841504Z","shell.execute_reply":"2025-01-19T16:17:05.847882Z"}},"outputs":[],"execution_count":null}]}